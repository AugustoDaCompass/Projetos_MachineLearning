# -*- coding: utf-8 -*-
"""PROJETOYOUTUBE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/142ZMQk812A54qrcDxPmNMUJGDHiCQNgV
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('adult.csv')
print(df)

df = pd.concat([df.drop('occupation',axis=1),pd.get_dummies(df.occupation).add_prefix('occupation_')],axis=1)
df = pd.concat([df.drop('workclass',axis=1),pd.get_dummies(df.workclass).add_prefix('workclass_')],axis=1)
df = pd.concat([df.drop('marital-status',axis=1),pd.get_dummies(df['marital-status']).add_prefix('marital-status_')],axis=1)
df = pd.concat([df.drop('relationship',axis=1),pd.get_dummies(df.relationship).add_prefix('relationship_')],axis=1)
df = pd.concat([df.drop('race',axis=1),pd.get_dummies(df.race).add_prefix('race_')],axis=1)
df = df.drop('education',axis=1)
df = pd.concat([df.drop('native-country',axis=1),pd.get_dummies(df['native-country']).add_prefix('native-country_')],axis=1)

df.head()

df['gender'] = df['gender'].apply(lambda x: 1 if x == 'Male' else 0)
df['income'] = df['income'].apply(lambda x: 1 if x == '>50K' else 0)

df

plt.figure(figsize=(18,12))
sns.heatmap(df.corr(),annot=False,cmap='coolwarm')

correlacao = df.corr()['income'].abs()
sorted_correlacao = correlacao.sort_values()
colunas_para_excluir = int(0.8 * len(df.columns))
colunas_excluidas = sorted_correlacao.iloc[:colunas_para_excluir].index
df_dropped = df.drop(colunas_excluidas, axis=1)

plt.figure(figsize=(15,10))
sns.heatmap(df_dropped.corr(),annot=True,cmap='coolwarm')

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

##df = df.drop('fnlwgt',axis=1)

train_df,test_df = train_test_split(df,test_size=0.2)



train_x = train_df.drop('income',axis=1)
train_y = train_df['income']

test_x = train_df.drop('income',axis=1)
test_y =train_df['income']


forest = RandomForestClassifier()

forest.fit(train_x,train_y)





forest.score(test_x,test_y)

forest.feature_importances_

importancia =  dict(zip(forest.feature_names_in_,forest.feature_importances_))
importancia = {k: v for k,v in sorted(importancia.items(), key=lambda x:[1],reverse=True)}

importancia

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50,100,250],
    'max_depth': [5,10,30,None],
    'min_samples_split': [2,4],
    'max_features': ['sqrt','log2']

}

grid_search = GridSearchCV(estimator=RandomForestClassifier(),param_grid= param_grid,verbose = 10)
grid_search.fit(train_x,train_y)

